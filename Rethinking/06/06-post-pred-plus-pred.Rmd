---
title: "Posterior Predictive Distribution + A PREDICTOR"
author: "STAT 341, Spring 2023"
date: "2023-02-10"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_download: yes
    self_contained: yes
    code_folding: show
  pdf_document:
    toc: yes
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggformula)
library(rethinking)
knitr::opts_chunk$set(echo = TRUE)
theme_set(theme_minimal(base_size = 16))
fiji <- read_csv('https://sldr.netlify.app/data/fiji-filters.csv') |> mutate(household_annual_income = household_annual_income / 1000)
```

## Model

Recall Prof DR's model for Fijian income:

$$\text{annual income}_i \sim \text{Normal}(\mu, \sigma)$$
$$\mu \sim \text{Normal}(\text{mean}_1 = 50, \text{sd}_1 = 20)$$
$$\sigma \sim \text{Normal}(\text{mean}_2 = 15, \text{sd}_2 = 20)$$ We
can fit the model with `quap()`.

```{r, r-model-descrip}
model_descrip <- alist(
  # note variable name has to match actual data variable name
  household_annual_income ~ dnorm(mu, sigma),
  mu ~ dnorm(mean = 50, sd = 20),
  sigma ~ dnorm(mean = 15, sd = 20)
)

quap_income_model <- quap(flist = model_descrip,
                          data = fiji)
quap_income_post_sample <- extract.samples(quap_income_model, n = 1000)
```

If we look at the posterior sample, we can get an idea of our estimates
of the *mean* and *standard deviation* of incomes:

```{r, message = FALSE, warning = FALSE}
gf_dens(~mu, data = quap_income_post_sample)
gf_dens(~sigma, data = quap_income_post_sample)
```

But what about the distribution of *incomes* we might expect?
Specifically, if we simulate many datasets (the same size as our real
`fiji` one), how do those distributions compare to the observed
distribution of the real data? Do they seem to match up well?

```{r, generate-posterior-pred-dist}
income_ppred <- quap_income_post_sample |>
  # add row numbers to "label" each sampled combo of mu & sigma
  mutate(row_num = c(1:n())) |>
  # work one row (one mu, sigma combination) at a time
  rowwise() |>
  # simulate a dataset for each row (= each mu, sigma combo)  
  mutate(ppred = list(rnorm(nrow(fiji), 
                            mean = mu,
                            sd = sigma))) |>
  # keep only the row-ids and the simulated data
  select(row_num, ppred) 

# note the structure: each row's ppred is a LIST of incomes nrow(fiji) long
glimpse(income_ppred)
```

```{r, unnest-ppred}
# "unnest" results so each observed income is in its own row instead of a list. Now there are nrow(fiji) rows for each mu, sigma combo
income_ppred <- income_ppred |>
  unnest(cols = ppred)

# peek at the final result
glimpse(income_ppred)
```

```{r, graph-ppreds}
# graph simulated datasets - one line for each mu,sigma combo
# this will take a while unless you reduce n above in extract.samples()!
gf_dens(~ppred, group = ~row_num, 
        data = income_ppred,
        alpha = 0.1) |>
  # overlay actual data
  gf_dens(~household_annual_income,
          data = fiji,
          inherit = FALSE,
          color = 'darkorange',
          linewidth = 1.5)
```

#### Question: Is this good, or bad? What is going on?

> Our posterior prediction distribution is lower and more spread out
> than the actual data.
>
> I think this is bad because the posterior predictive distribution is
> not capturing the true data? I'm not sure

*Stay tuned for Homework 4 for some progress...*

#### Task: Generate a posterior predictive distribution for your `water_expenses_pp` model fitted with `quap()`.

```{r}
model_descrip <- alist(
  # note variable name has to match actual data variable name
  water_expenses_pp ~ dnorm(mu, sigma),
  mu ~ dnorm(mean = 10, sd = 3),
  sigma ~ dunif(min = 0, max = 3)
)

quap_water_expenses_model <- quap(flist = model_descrip,
                          data = fiji)
quap_water_expenses_post_sample <- extract.samples(quap_water_expenses_model, n = 1000)
```

```{r, message = FALSE, warning = FALSE}
gf_dens(~mu, data = quap_water_expenses_post_sample)
gf_dens(~sigma, data = quap_water_expenses_post_sample)
```

```{r}
water_expenses_ppred <- quap_water_expenses_post_sample |>
  # add row numbers to "label" each sampled combo of mu & sigma
  mutate(row_num = c(1:n())) |>
  # work one row (one mu, sigma combination) at a time
  rowwise() |>
  # simulate a dataset for each row (= each mu, sigma combo)  
  mutate(ppred = list(rnorm(nrow(fiji), 
                            mean = mu,
                            sd = sigma))) |>
  # keep only the row-ids and the simulated data
  select(row_num, ppred) 

# note the structure: each row's ppred is a LIST of incomes nrow(fiji) long
glimpse(water_expenses_ppred)
```

```{r}
# "unnest" results so each observed income is in its own row instead of a list. Now there are nrow(fiji) rows for each mu, sigma combo
water_expenses_ppred <- water_expenses_ppred |>
  unnest(cols = ppred)

# peek at the final result
glimpse(water_expenses_ppred)
```

```{r}
# graph simulated datasets - one line for each mu,sigma combo
# this will take a while unless you reduce n above in extract.samples()!
gf_dens(~ppred, group = ~row_num, 
        data = water_expenses_ppred,
        alpha = 0.1) |>
  # overlay actual data
  gf_dens(~water_expenses_pp,
          data = fiji,
          inherit = FALSE,
          color = 'darkorange',
          linewidth = 1.5)
```

## Predictor!

We want to reach a point where we can model *multiple* variables at a
time, and quantify their associations (if any).

Once we have more than 2 we will use causal diagrams to guide our model
design and decide which variables to include in a model.

We will start, for now, with just two variables though. Consider the
variable you've been working with (`houshold_annual_income` for me,
`water_expenses_pp` for you) as the response variable.

#### Task: identify one quantitative variable that could be a predictor of your response.

> I will choose `n_total` as a possible predictor since I think having
> multiple potential water consumer in the house will lead to higher
> water expense for the group.

*For `household_annual_income`, I will choose `n_adults` as a possible
predictor since I think having multiple potential earners in the house
will lead to higher incomes for the group.*

My model will now be:

$$\text{household annual income}_i \sim \text{Normal}(\mu_i, \sigma)$$
$$\mu_i \sim \beta_0 + \beta_1 * \text{n adults}$$
$$\beta_0 \sim \text{Normal}(30,20)$$
$$\beta_1 \sim \text{Normal}(20, 10)$$
$$\sigma \sim \text{Normal}(15,20)$$

Now, the *first two* lines of the description state the structure of the
model and tell how the likelihood will be determined. The last three are
all priors.

#### Question: Can you state in words what each line of the description means? For priors, include statements in terms of income dollars, people, etc.

> 1.  Household annual income is normally distributed with mean $\mu_i$
>     and $\sigma$.
> 2.  The $\mu_i$ is base income $\beta_0$ + additional income per adult
>     $\beta_1$ \* b adults.
> 3.  Prior base income per household $\beta_0$ is normally distributed
>     with a mean of 30000 dollars and a standard deviation of 20000
>     dollars.
> 4.  Prior additional income per adult $\beta_1$ is normally
>     distributed with a mean of 20000 dollars and a standard deviation
>     of 10000 dollars.
> 5.  The standard deviation of household annual income is normally
>     distributed with a mean of 15000 dollars and a standard deviation
>     of 20000 dollars

#### Question: What's with the $i$ subscripts?

> Different $\mu_i$ represents different individual household.

#### Question: $\text{Normal}(0,\sigma)$ is often considered an "uninformative" prior for $\beta_1$. Can you explain why, in words? Why didn't I use it here?

> An uninformative prior is a prior that has minimal influence on the
> inference.
>
> $\text{Normal}(0, \sigma)$ is often considered an "uninformative"
> prior because it assumes no prior knowledge about the parameter,
> allowing the data to influence the posterior more.
>
> You didn't use it here because each additional adult increases income,
> so you want to have a more informative prior.

#### Task: Generate a prior predictive distribution for this model. (Start with the code above for the *posterior* predictive distribution -- but you'll need to generate your own draws from the priors instead of starting with a posterior sample.) Describe (or implement) any changes you think are needed.

```{r}
n_samples <- 10000

beta_0_prior <- rnorm(n_samples, mean = 30, sd = 20)
beta_1_prior <- rnorm(n_samples, mean = 20, sd = 10)
sigma_prior <- abs(rnorm(n_samples, mean = 15, sd = 20)) 

mu_prior <- beta_0_prior + beta_1_prior * mean(fiji$n_adults, na.rm = TRUE)
prior_predictive_distribution <- rnorm(n_samples, mean = mu_prior, sd = sigma_prior)

gf_histogram(~prior_predictive_distribution)
```

```{r, warning = FALSE}
# Number of prior predictive samples
n_samples <- 10000

prior_samples <- tibble(
  beta_0 = rnorm(n_samples, mean = 30, sd = 20),
  beta_1 = rnorm(n_samples, mean = 20, sd = 10),
  sigma = abs(rnorm(n_samples, mean = 15, sd = 20))  
)

prior_ppred <- prior_samples |>
  # add row numbers to "label" each sampled combo of beta_0, beta_1, and sigma
  mutate(row_num = c(1:n_samples)) |>
  # work one row (one beta_0, beta_1, sigma combination) at a time
  rowwise() |>
  # simulate a dataset for each row (= each beta_0, beta_1, sigma combo)
  mutate(ppred = list(rnorm(nrow(fiji),
                            mean = beta_0 + beta_1 * fiji$n_adults,
                            sd = sigma))) |>
  # keep only the row-ids and the simulated data
  select(row_num, ppred)

# "unnest" results so each observed income is in its own row instead of a list. Now there are nrow(fiji) rows for each beta_0, beta_1, sigma combo
prior_ppred <- prior_ppred |>
  unnest(cols = ppred)

# Peek at the final result
glimpse(prior_ppred)
```

```{r}
gf_dens(~ppred, group = ~row_num, 
        data = prior_ppred,
        alpha = 0.1) |>
  # overlay actual data
  gf_dens(~household_annual_income,
          data = fiji,
          inherit = FALSE,
          color = 'darkorange',
          linewidth = 1.5)
```

#### Task: Fit this model using `quap()`. (Code is given below if you need it - for more challenge try to do it on your own.)

```{r, message = FALSE, warning = FALSE}
hh_size_income_mod <- quap(
  flist = alist(
    household_annual_income ~ dnorm(mu, sigma),
    mu ~ b0 + b1 * n_adults,
    b0 ~ dnorm(30,20),
    b1 ~ dnorm(20,10),
    sigma ~ dnorm(15,20)
  ),
  data = fiji)
precis(hh_size_income_mod)
```

#### Task/Question: generate and plot a posterior sample and a posterior predictive distribution. What do you think?

```{r, message = FALSE, warning = FALSE}
model_descrip <- alist(
  household_annual_income ~ dnorm(mu, sigma),
  mu <- beta_0 + beta_1 * n_adults,
  beta_0 ~ dnorm(mean = 30, sd = 20),
  beta_1 ~ dnorm(mean = 20, sd = 10),
  sigma ~ dnorm(mean = 15, sd = 20)
)

quap_income_model <- quap(flist = model_descrip,
                          data = fiji)
quap_income_post_sample <- extract.samples(quap_income_model, n = 1000)

gf_dens(~beta_0, data = quap_income_post_sample) 
gf_dens(~beta_1, data = quap_income_post_sample)
gf_dens(~sigma, data = quap_income_post_sample) 
```

```{r}
posterior_ppred <- quap_income_post_sample |>
  # add row numbers to "label" each sampled of beta_0, beta_1, and sigma
  mutate(row_num = c(1:n())) |>
  # work one row (one beta_0, beta_1, sigma combination) at a time
  rowwise() |>
  # simulate a dataset for each row (= each beta_0, beta_1, sigma combo)
  mutate(ppred = list(rnorm(nrow(fiji),
                            mean = beta_0 + beta_1 * fiji$n_adults,
                            sd = sigma))) |>
  # keep only the row-ids and the simulated data
  select(row_num, ppred)

# note the structure: each row's ppred is a LIST of incomes nrow(fiji) long
glimpse(posterior_ppred)
```

```{r}
# "unnest" results so each observed income is in its own row instead of a list. Now there are nrow(fiji) rows for each beta_0, beta_1, sigma combo
posterior_ppred <- posterior_ppred |>
  unnest(cols = ppred)

# Peek at the final result
glimpse(posterior_ppred)
```

```{r}
# graph simulated datasets - one line for each mu,sigma combo
# this will take a while unless you reduce n above in extract.samples()!
gf_dens(~ppred, group = ~row_num, 
        data = posterior_ppred,
        alpha = 0.1) |>
  # overlay actual data
  gf_dens(~household_annual_income,
          data = fiji,
          inherit = FALSE,
          color = 'darkorange',
          linewidth = 1.5)
```

## What's next?

Think about how you might change or expand this model.

-   How would the code look to fit a model with *more* predictors?
-   Where might you want to use other distributions - which ones, and
    why?
-   The model we tried hypothesized a *linear* association between
    `n_adults` and income. How could we model other situations (for
    example: nonlinear, variability that increases as the mean income
    increases, your other ideas?) These additions to the model are
    **much** easier in a Bayesian framework than a frequentist one!

## Practice

For your `water_expenses_pp`,

-   Describe a model with one predictor
-   Generate a prior predictive distribution
-   Fit the model using `quap()`
-   Sample from the posterior and graph the result
-   Generate a posterior predictive distribution
