---
title: "fat"
author: "STAT 341, Feb. 13, 2023"
date: ""
output:
  html_document:
    toc: true
    toc_float: true
    code_download: true
  pdf_document: default
---

```{r setup, include=FALSE, message=FALSE}
library(faraway)
library(tidyverse)
library(rethinking)
library(CalvinBayes)
library(tidybayes)
library(rethinking)
library(ggformula)
library(bayesplot)
library(mosaic)
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(faraway)
# head(fat)
# for more info, type in the R console:
# ?fat
```

## Instructions

Choose one or more of the options below to practice linear regression. Save your group's work in an Rmd file (that you may later present to the class). The process:

-   Choose a response variable and a single main predictor. Have a rationale for your choices (even if it's not written down in detail).

    > main predictor: `density`
    >
    > response: `brozek`

-   Sketch (by pencil or using `dagitty`) a **causal diagram** for this situation. You may want to include other variables from the dataset, or even ones that you *don't* have data on. By using just one predictor and the response, what other key covariates might you be ignoring (if any)?

![casual diagram?](casual_diagram.png)

-   Write out a **description of a model** including your predictor and response variables (only). Use a normal distribution to model your response (your choice of distribution(s) for priors). If needed, use internet research to get background and select priors.

    > $$\text{brozek_i} \sim \text{Normal}(\mu_i, \sigma^2)$$ $$\mu_i \sim \beta_0 + \beta_1 * \text{density_i}$$ $$\beta_0 \sim \text{Normal}(0, 10)$$ $$\beta_1 \sim \text{Normal}(0, 10)$$ $$\sigma \sim \text{Uniform}(0, 2)$$

-   Now you can peek at the data...consider making a scatter plot of the response vs the predictor. (`gf_point(response ~ predictor, data = dataset_name)` will do it for you.)

    ```{r}
    gf_point(brozek ~ density, data = fat)
    ```

-   Do a **prior predictive check** (generate a prior predictive distribution as a reality check for your priors.

    ```{r}
    nsim <- 1000

    beta_0_prior <- rnorm(nsim, mean = 0, sd = 10)
    beta_1_prior <- rnorm(nsim, mean = 0, sd = 10)
    sigma_prior <- abs(rnorm(nsim, mean = 0, sd = 2))  


    density_values <- seq(0.5, 1.5, length.out = 100)  

    prior_pred_dist <- tibble(
      beta_0 = sample(beta_0_prior, nsim, replace = TRUE),
      beta_1 = sample(beta_1_prior, nsim, replace = TRUE),
      sigma = sample(sigma_prior, nsim, replace = TRUE),
      density = sample(density_values, nsim, replace = TRUE)
    ) |>
      rowwise() |>
      mutate(
        brozek = rnorm(1, mean = beta_0 + beta_1 * density, sd = sigma)
      ) |>
      ungroup()

    gf_histogram(~brozek,
                 data = prior_pred_dist, binwidth = 1)

    ```

-   Use `quap()` to fit your model.

-   Think about how you might graph your **posterior distributions.** You can at least make a density plot or two. But...what do those mean? Are they easy to interpret? What is *really* most relevant to show? Consider carefully and sketch what you'd *want* to show. If you are bold and confident with your R skills, you can consider also making the graphs you envision. (Stay tuned for Wednesday.)

-   Maybe, for extra challenge: Generate and graph a **posterior predictive distribution**, comparing it with your observed data.

-   Considering all you have done...what can you conclude?
